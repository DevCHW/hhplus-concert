# 부하 테스트 보고서

## 부하 테스트 대상 API 선정

### 전체 API 리스트업

| Method |                                 Endpoint                                  |    Description     | Domain |
|:------:|:-------------------------------------------------------------------------:|:------------------:|:------:|
|  GET   |                              /api/v1/balance                              |       잔고 조회        |   잔고   |
|  PUT   |                          /api/v1/balance/charge                           |       잔고 충전        |   잔고   |
|  GET   |                             /api/v1/concerts                              |     콘서트 목록 조회      |  콘서트   |
|  GET   |                         /api/v1/concerts/popular                          |     인기 콘서트 조회      |  콘서트   |
|  GET   | /api/v1/concerts/{concertId}/schedules/{concertScheduled}/seats/available |   예약 가능 좌석 목록 조회   |  콘서트   |
|  GET   |             /api/v1/concerts/{concertId}/schedules/available              | 예약 가능 콘서트 일정 목록 조회 |  콘서트   |
|  POST  |                           /api/v1/reservations                            |     콘서트 좌석 예약      |   예약   |
|  POST  |                         /api/v1/reservations/pay                          |       예약 결제        |   예약   |
|  POST  |                            /api/v1/queue/token                            |     대기열 토큰 생성      |  대기열   |
|  GET   |                            /api/v1/queue/token                            |     대기열 토큰 조회      |  대기열   |

### 부하 테스트 대상 API 선정

1. `POST /api/v1/queue/token`
- 이유:  대기열에서 사용자가 토큰을 발급받는 API로, 대량의 트래픽을 받는 핵심 진입점입니다. 동시 요청이 급증할 경우 서버의 처리 성능과 대기열 관리 시스템의 안정성을 평가할 필요가 있습니다.
2. `GET /api/v1/queue/token`
- 이유: 사용자가 현재 대기열에서의 상태를 조회하는 API로, 반복적인 호출이 예상됩니다. 부하 테스트를 통해 서버 및 Redis 조회 성능을 평가하고, 특정 구간에서의 응답 속도를 최적화할 필요가 있습니다.

## 테스트 환경 설정

### 장비 및 시스템 환경

- OS: macOS 15.1
- CPU: Apple M3
- Memory (RAM): 16GB
- Storage: 512GB SSD
- Docker: OrbStack
- Docker Engine: 27.5.1
- Docker Compose: v2.32.4

### 부하테스트 환경 docker-compose 설정

> 부하테스트 대상 서버 어플리케이션은 AWS EC2 t3.medium 기준(2 vCPU, 4 GIB 메모리)를 기준으로 설정.  
> []() 참고.

- 어플리케이션:
    - 메모리 제한: 4G
    - CPU 코어 수: 2

- MySQL:
    - Image: [mysql](https://hub.docker.com/_/mysql)
    - Tag: 8.0

- Redis:
    - Image: [redis](https://hub.docker.com/_/redis)
    - Tag: 6.2.6

- Kafka:
    - Image: [confluentinc/cp-kafka](https://hub.docker.com/r/confluentinc/cp-kafka/tags)
    - Tag: 7.9.0

- Zookeeper
    - 이미지: [cp-zookeeper](https://hub.docker.com/r/confluentinc/cp-zookeeper)
    - Tag: 7.9.0

### 테스트 및 모니터링 툴
- K6: 3.10.3
- Prometheus: 3.2.1
- Grafana: 11.5.2
- InfluxDB: 1.11

## 테스트 시나리오 및 수행 결과 분석

### 1. `POST /api/v1/queue/token`: 대기열 토큰 생성

#### 테스트 시나리오
- 목적: 
  - 대량의 동시 요청이 발생할 경우, 대기열 시스템이 정상적으로 토큰을 발급할 수 있는지 검증
  - 요청이 몰릴 때 API의 응답 속도 및 실패율 분석
  - 대기열 서비스가 안정적으로 작동하는지 평가
- 테스트 흐름:
  - 다수의 사용자가 동시에 대기열에 진입 시도
  - 서버가 대기열 토큰을 정상적으로 발급하는지 확인
- 부하 조건
  - 유저 수: 최대 500명
  - 지속 시간: 160초
  - 예상 트래픽: 
    - 평균 TPS: 약 500 TPS
    - 최대 TPS: 약 500 ~ 700 TPS (테스트 중 실제 측정값 확인 필요)
    - 총 요청 수: 약 80,000 ~ 100,000 요청 예상 (VU 및 응답 속도에 따라 변동 가능)

- 성능 지표 분석
  - ```
         ✗ is status 200
        ↳  99% — ✓ 105191 / ✗ 54
       ✗ response time < 500ms
        ↳  99% — ✓ 105244 / ✗ 1

       checks.........................: 99.97% 210435 out of 210490
       data_received..................: 23 MB  142 kB/s
       data_sent......................: 20 MB  122 kB/s
       errors.........................: 55     0.342771/s
       http_req_blocked...............: avg=24.76µs  min=583ns    med=2µs      max=1s       p(90)=5.29µs   p(95)=8.7µs   
       http_req_connecting............: avg=19.51µs  min=0s       med=0s       max=1s       p(90)=0s       p(95)=0s      
     ✓ http_req_duration..............: avg=3.96ms   min=319.59µs med=1.74ms   max=999.94ms p(90)=6.61ms   p(95)=10.87ms 
         { expected_response:true }...: avg=3.95ms   min=319.59µs med=1.73ms   max=999.94ms p(90)=6.6ms    p(95)=10.87ms 
     ✓ http_req_failed................: 0.05%  54 out of 105245
       http_req_receiving.............: avg=31.12µs  min=3.04µs   med=11.66µs  max=10.23ms  p(90)=60.78µs  p(95)=106.47µs
       http_req_sending...............: avg=18.54µs  min=2µs      med=5.62µs   max=7.92ms   p(90)=23.49µs  p(95)=53.61µs 
       http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s      
       http_req_waiting...............: avg=3.91ms   min=302.13µs med=1.7ms    max=999.88ms p(90)=6.51ms   p(95)=10.73ms 
       http_reqs......................: 105245 655.907112/s
       iteration_duration.............: avg=504.71ms min=500.46ms med=502.46ms max=1.5s     p(90)=507.74ms p(95)=512ms   
       iterations.....................: 105245 655.907112/s
       vus............................: 103    min=5                max=500
       vus_max........................: 500    min=500              max=500
    ```
    - 평균 요청 처리 속도: 655.91 TPS (초당 요청 수)
    - 평균 응답 시간: 3.96ms
    - 최대 응답 시간: 999.94ms
- 개선할 점:
  - 일부 요청 응답 지연 (max=999.94ms)
  - 54건의 요청 실패 (0.05% 오류율)
    - 개선 방안: 서버 로그 분석 필요
  - 일부 요청 차단 (http_req_blocked max=1s)
    - 개선 방안: 스레드 풀 부족 가능성, API 서버의 쓰레드 풀 크기 조정 (tomcat.maxThreads)
      
- 결론
  - 목표 TPS(500)보다 높은 수치(654.8 TPS) 달성
  - 가용성: 99.95% 
  - 낮은 지연율: (평균 3.96ms)
  - 일부 요청에서 최대 응답 시간(999.59ms) 발생 → 순간적인 부하 증가 원인 분석 필요
  - 향후 더 높은 처리량 요구시 서버 Scale-Up, Scale-Out 및 Redis 클러스터 구성을 고려할 수 있음


### 2. `GET /api/v1/queue/token`: 대기열 토큰 조회 
#### 테스트 시나리오
- 목적:
  - 대기열 토큰 조회 API의 성능을 검증하고, 예상 트래픽을 처리할 수 있는지 확인합니다.
  - 평균 및 최대 TPS를 측정하여 시스템의 부하 대응 능력을 평가합니다.
  - 응답 속도 및 에러율을 분석하여 병목 현상이 발생하는지 확인합니다.
- 테스트 흐름:
  - 500명의 가상 유저(Virtual Users, VU)가 동시 접속하여 GET /api/v1/queue/token API를 호출합니다.
  - 160초 동안 지속적으로 요청을 발생시킵니다.
- 부하 조건
  - 유저 수: 최대 500명
  - 지속 시간: 160초
  - 예상 트래픽:
    - 평균 TPS: 약 500 TPS
    - 최대 TPS: 약 500 ~ 700 TPS (테스트 중 실제 측정값 확인 필요)
    - 총 요청 수: 약 80,000 ~ 100,000 요청 예상 (VU 및 응답 속도에 따라 변동 가능)
- 성능 지표 분석
  - ```
         ✓ is status 200
         ✗ response time < 500ms
          ↳  99% — ✓ 105089 / ✗ 1
  
         checks.........................: 99.99% 210179 out of 210180
         data_received..................: 23 MB  141 kB/s
         data_sent......................: 23 MB  144 kB/s
         errors.........................: 1      0.006231/s
         http_req_blocked...............: avg=67.16µs  min=625ns    med=2.37µs   max=1s       p(90)=6.7µs    p(95)=11.41µs 
         http_req_connecting............: avg=60.89µs  min=0s       med=0s       max=1s       p(90)=0s       p(95)=0s      
        ✓ http_req_duration..............: avg=4.53ms   min=318.75µs med=1.79ms   max=999.59ms p(90)=6.43ms   p(95)=10.03ms
        { expected_response:true }...: avg=4.53ms   min=318.75µs med=1.79ms   max=999.59ms p(90)=6.43ms   p(95)=10.03ms
        ✓ http_req_failed................: 0.00%  0 out of 105090
          http_req_receiving.............: avg=36.87µs  min=3.33µs   med=13.41µs  max=34.42ms  p(90)=71.06µs  p(95)=123.96µs
          http_req_sending...............: avg=20.55µs  min=1.91µs   med=6.37µs   max=34.8ms   p(90)=27.28µs  p(95)=62.12µs
          http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s      
          http_req_waiting...............: avg=4.47ms   min=291.87µs med=1.74ms   max=999.5ms  p(90)=6.33ms   p(95)=9.92ms  
          http_reqs......................: 105090 654.799751/s
          iteration_duration.............: avg=505.48ms min=500.39ms med=502.53ms max=1.51s    p(90)=507.74ms p(95)=511.47ms
          iterations.....................: 105090 654.799751/s
          vus............................: 104    min=5                max=500
          vus_max........................: 500    min=500              max=500
    ```
- 결론
  - 목표 TPS(500)보다 높은 수치(654.8 TPS) 달성
  - 100% 가용성 (오류 없음, 105,090건 전부 정상 응답)
  - 낮은 지연율: 평균 응답 시간 4.53ms, P(95) 기준 10.03ms
  - 최대 응답 시간(999.59ms) 지연 발생 → 순간적인 부하 증가 원인 분석 필요
  - 이후 좀 더 높은 처리량을 요구한다면 서버 Scale-Up, Scale-Out 및 Redis 클러스터링 검토 필요